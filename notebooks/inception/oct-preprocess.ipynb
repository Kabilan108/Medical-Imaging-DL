{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Colab Notebook Set Up\n",
    "\n",
    "Use this cell to upload your kaggle.json file as well as the `download_data.sh`\n",
    "and `preprocess.py` scripts.\n",
    "\"\"\"\n",
    "\n",
    "from google.colab import files, drive\n",
    "import os\n",
    "\n",
    "# Mount google drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Upload files\n",
    "kaggle = files.upload()\n",
    "data_script = files.upload()\n",
    "preprocess_script = files.upload()\n",
    "config = files.upload()\n",
    "\n",
    "# Verify uploads\n",
    "for file in [\"kaggle.json\", \"download_data.sh\", \"preprocess.py\", \"oct.yaml\"]:\n",
    "    assert file in os.listdir(), f\"Make sure you upload the {file} file\"\n",
    "\n",
    "# Shell commands (files)\n",
    "!mkdir -p ~/.kaggle/ data/ models/ config/ scripts/ net/\n",
    "!mv kaggle.json ~/.kaggle/\n",
    "!mv download_data.sh preprocess.py scripts/\n",
    "!mv oct.yaml config/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "!chmod +x scripts/download_data.sh scripts/preprocess.py\n",
    "!sed -i -e 's/\\r$//' scripts/download_data.sh\n",
    "!pip install -q kaggle pretrainedmodels rich\n",
    "!touch net/__init__.py net/train.py net/utils.py\n",
    "\n",
    "# Run shell commands\n",
    "!scripts/download_data.sh\n",
    "!python scripts/preprocess.py --config config/oct.yaml --kw batch-size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning InceptionV3 for Retinal OCT Images\n",
    "\n",
    "### Context\n",
    "\n",
    "- Retinal Optical Coherence Tomography (OCT) is an imaging technique used to\n",
    "  capture high-res cross sections of the retina\n",
    "- ~84, 495 OCT Images in total\n",
    "\n",
    "### Content\n",
    "\n",
    "- Images in JPEG format with 3 channels, i.e., RGB\n",
    "- 4 categories: CNV, DME, DRUSEN, NORMAL\n",
    "\n",
    "### This Notebook\n",
    "\n",
    "- Fine-tune InceptionV3 by training the last, linear layer on the new data\n",
    "- The images are pre-processed by running the forward pass through the\n",
    "  InceptionV3 network and saving the output of the last pooling layer\n",
    "  (2048-dimensional vector) to disk.\n",
    "  - These feature vectors are then used to train a single-layer linear\n",
    "    classifier on the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "import torch\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "from rich import print\n",
    "from glob import glob\n",
    "\n",
    "import sys; sys.path.append(\".\")\n",
    "from net import train, utils\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "import yaml\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "config = \"config/oct.yaml\"\n",
    "with open(config, 'r') as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset to load InceptionV3 features for fine-tuning\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, feature_dir):\n",
    "        self.files = sorted(glob(f\"{feature_dir}/FL*.npy\"), key=self._extract_idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label, feature = np.load(self.files[idx], allow_pickle=True)\n",
    "        return torch.from_numpy(feature), torch.from_numpy(label)\n",
    "\n",
    "    def _extract_idx(self, filename):\n",
    "        \"\"\"Extract batch index from filename\"\"\"\n",
    "        match = re.search(r\"(\\d+)\\.npy$\", filename)\n",
    "        match = int(match.group(1)) if match else -1\n",
    "        if match == -1:\n",
    "            raise ValueError(f\"Invalid filename {filename}\")\n",
    "        return match\n",
    "\n",
    "\n",
    "# Create datasets\n",
    "data = {\n",
    "    \"train\": FeatureDataset(config[\"features\"][\"train\"]),\n",
    "    \"test\": FeatureDataset(config[\"features\"][\"test\"]),\n",
    "    \"val\": FeatureDataset(config[\"features\"][\"val\"])\n",
    "}\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 1024\n",
    "dataloaders = {\n",
    "    \"train\": DataLoader(data[\"train\"], batch_size=batch_size, shuffle=True),\n",
    "    \"test\": DataLoader(data[\"test\"], batch_size=batch_size, shuffle=False),\n",
    "    \"val\": DataLoader(data[\"val\"], batch_size=batch_size, shuffle=False)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FineTuned(nn.Module):\n",
    "    \"\"\"Fine-tuned output layer for InceptionV3\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(FineTuned, self).__init__()\n",
    "        self.fc = nn.Linear(2048, config[\"num_classes\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "model = FineTuned(config)\n",
    "model.to(train.device())\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "# optimizer = optim.SGD(model.parameters(), lr=config[\"lr\"], momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize training and logging\n",
    "timestamp = datetime.now().strftime(\"%m%d_%H%M%S\")\n",
    "writer = SummaryWriter(f\"logs/inception/oct-{timestamp}\")\n",
    "EPOCH = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "EPOCH += num_epochs\n",
    "\n",
    "model, history = train.train_model(\n",
    "    model, dataloaders, criterion, optimizer, num_epochs, EPOCH, writer,\n",
    "    is_inception=False\n",
    ")\n",
    "\n",
    "torch.save(model.state_dict(), f\"models/oct-preprocess-{timestamp}.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
